<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>AIBS grant peer review scoring dataset — AIBS • ShinyItemAnalysis</title><!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png"><link rel="icon" type="”image/svg+xml”" href="../favicon.svg"><link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png"><link rel="icon" sizes="any" href="../favicon.ico"><link rel="manifest" href="../site.webmanifest"><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="AIBS grant peer review scoring dataset — AIBS"><meta name="description" content="The AIBS dataset (Gallo, 2020) comes from the scientific peer review
facilitated by the American Institute of Biological Sciences (AIBS) of
biomedical applications from and intramural collaborative biomedical research
program for 2014–2017. For each proposal, three assigned individual
reviewers were asked to provide scores and commentary for the following
application criteria: Innovation, Approach/Feasibility, Investigator, and
Significance (Impact added as scored criterion in 2014). Each of these
criteria is scored on a scale from 1.0 (best) to 5.0 (worst) with a 0.1
gradation, as well as an overall score (1.0–5.0 with a 0.1 gradation).
Asynchronous discussion was allowed, although few scores changed
post-discussion. The data includes reviewers' self-reported expertise scores
(1/2/3, 1 is high expertise) relative to each proposal reviewed, and reviewer
/ principal investigator demographics. A total of 72 applications (&quot;Standard&quot;
or &quot;Pilot&quot;) were reviewed in 3 review cycles. The success rate was 34–38 %.
Application scores indicate where each application falls among all
practically possible applications in comparison with the ideal standard of
quality from a perfect application. The dataset was used by Erosheva et al.
(2021a) to demonstrate issues of inter-rater reliability in case of
restricted samples. For details, see Erosheva et al. (2021b)."><meta property="og:description" content="The AIBS dataset (Gallo, 2020) comes from the scientific peer review
facilitated by the American Institute of Biological Sciences (AIBS) of
biomedical applications from and intramural collaborative biomedical research
program for 2014–2017. For each proposal, three assigned individual
reviewers were asked to provide scores and commentary for the following
application criteria: Innovation, Approach/Feasibility, Investigator, and
Significance (Impact added as scored criterion in 2014). Each of these
criteria is scored on a scale from 1.0 (best) to 5.0 (worst) with a 0.1
gradation, as well as an overall score (1.0–5.0 with a 0.1 gradation).
Asynchronous discussion was allowed, although few scores changed
post-discussion. The data includes reviewers' self-reported expertise scores
(1/2/3, 1 is high expertise) relative to each proposal reviewed, and reviewer
/ principal investigator demographics. A total of 72 applications (&quot;Standard&quot;
or &quot;Pilot&quot;) were reviewed in 3 review cycles. The success rate was 34–38 %.
Application scores indicate where each application falls among all
practically possible applications in comparison with the ideal standard of
quality from a perfect application. The dataset was used by Erosheva et al.
(2021a) to demonstrate issues of inter-rater reliability in case of
restricted samples. For details, see Erosheva et al. (2021b)."><meta property="og:image" content="/logo.svg"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">ShinyItemAnalysis</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.5.5</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/patriciamar/ShinyItemAnalysis/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>AIBS grant peer review scoring dataset</h1>
      <small class="dont-index">Source: <a href="https://github.com/patriciamar/ShinyItemAnalysis/blob/master/R/data_AIBS.R" class="external-link"><code>R/data_AIBS.R</code></a></small>
      <div class="d-none name"><code>AIBS.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>The <code>AIBS</code> dataset (Gallo, 2020) comes from the scientific peer review
facilitated by the American Institute of Biological Sciences (AIBS) of
biomedical applications from and intramural collaborative biomedical research
program for 2014–2017. For each proposal, three assigned individual
reviewers were asked to provide scores and commentary for the following
application criteria: Innovation, Approach/Feasibility, Investigator, and
Significance (Impact added as scored criterion in 2014). Each of these
criteria is scored on a scale from 1.0 (best) to 5.0 (worst) with a 0.1
gradation, as well as an overall score (1.0–5.0 with a 0.1 gradation).
Asynchronous discussion was allowed, although few scores changed
post-discussion. The data includes reviewers' self-reported expertise scores
(1/2/3, 1 is high expertise) relative to each proposal reviewed, and reviewer
/ principal investigator demographics. A total of 72 applications ("Standard"
or "Pilot") were reviewed in 3 review cycles. The success rate was 34–38 %.
Application scores indicate where each application falls among all
practically possible applications in comparison with the ideal standard of
quality from a perfect application. The dataset was used by Erosheva et al.
(2021a) to demonstrate issues of inter-rater reliability in case of
restricted samples. For details, see Erosheva et al. (2021b).</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="va">AIBS</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="format">Format<a class="anchor" aria-label="anchor" href="#format"></a></h2>
    <p><code>AIBS</code> is a <code>data.frame</code> consisting of 216 observations on
25 variables. Data describes 72 proposals with 3 ratings each.</p><dl><dt>ID</dt>
<dd><p>Proposal ID.</p></dd>

<dt>Year</dt>
<dd><p>Year of the review.</p></dd>

<dt>PropType</dt>
<dd><p>Proposal type; <code>"Standard"</code> or <code>"Pilot"</code>.</p></dd>

<dt>PIID</dt>
<dd><p>Anonymized ID of principal investigator (PI).</p></dd>

<dt>PIOrgType</dt>
<dd><p>PI's organization type.</p></dd>

<dt>PIGender</dt>
<dd><p>PI's gender membership; <code>"1"</code> females, <code>"2"</code> males.</p></dd>

<dt>PIRank</dt>
<dd><p>PI's rank; <code>"3"</code> full professor, <code>"1"</code> assistant professor.</p></dd>

<dt>PIDegree</dt>
<dd><p>PI's degree; <code>"1"</code> PhD, <code>"2"</code> MD, <code>"3"</code> PhD/MD.</p></dd>

<dt>Innovation</dt>
<dd><p>Innovation score.</p></dd>

<dt>Approach</dt>
<dd><p>Approach score.</p></dd>

<dt>Investig</dt>
<dd><p>Investigator score.</p></dd>

<dt>Signif</dt>
<dd><p>Significance score.</p></dd>

<dt>Impact</dt>
<dd><p>Impact score.</p></dd>

<dt>Score</dt>
<dd><p>Scientific merit (overall) score.</p></dd>

<dt>ScoreAvg</dt>
<dd><p>Average of the three overall scores from three different reviewers.</p></dd>

<dt>ScoreAvgAdj</dt>
<dd><p>Average of the three overall scores from three different reviewers, increased by multiple of 0.001 of the worst score.</p></dd>

<dt>ScoreRank</dt>
<dd><p>Project rank calculated based on <code>ScoreAvg</code>.</p></dd>

<dt>ScoreRankAdj</dt>
<dd><p>Project rank calculated based on <code>ScoreAvgAdj</code>.</p></dd>

<dt>RevID</dt>
<dd><p>Reviewer's ID.</p></dd>

<dt>RevExp</dt>
<dd><p>Reviewer's experience.</p></dd>

<dt>RevInst</dt>
<dd><p>Reviewer's institution; <code>"1"</code> academia, <code>"2"</code> government.</p></dd>

<dt>RevGender</dt>
<dd><p>Reviewer's gender; <code>"1"</code> females, <code>"2"</code> males.</p></dd>

<dt>RevRank</dt>
<dd><p>Reviewer's rank; <code>"3"</code> full professor, <code>"1"</code> assistant professor.</p></dd>

<dt>RevDegree</dt>
<dd><p>Reviewer's degree; <code>"1"</code> PhD, <code>"2"</code> MD, <code>"3"</code> PhD/MD.</p></dd>

<dt>RevCode</dt>
<dd><p>Reviewer code (<code>"A"</code>, <code>"B"</code>, <code>"C"</code>) in the original wide dataset.</p></dd>


</dl></div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>Gallo, S. (2021). Grant  peer  review  scoring  data  with  criteria  scores.
<a href="https://doi.org/10.6084/m9.figshare.12728087" class="external-link">doi:10.6084/m9.figshare.12728087</a></p>
<p>Erosheva, E., Martinkova, P., &amp; Lee, C. (2021a). When zero may not be zero: A
cautionary note on the use of inter-rater reliability in evaluating grant
peer review. Journal of the Royal Statistical Society - Series A.
<a href="https://doi.org/10.1111/rssa.12681" class="external-link">doi:10.1111/rssa.12681</a></p>
<p>Erosheva, E., Martinkova, P., &amp; Lee, C. (2021b). Supplementary material: When
zero may not be zero: A cautionary note on the use of inter-rater reliability
in evaluating grant peer review. <a href="https://doi.org/10.17605/OSF.IO/KNPH8" class="external-link">doi:10.17605/OSF.IO/KNPH8</a></p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="ICCrestricted.html">ICCrestricted()</a></code></p></div>
    </div>
    <div class="section level2">
    <h2 id="author">Author<a class="anchor" aria-label="anchor" href="#author"></a></h2>
    <p>Stephen Gallo <br> American Institute of Biological Sciences</p>
    </div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Patricia Martinkova, Adela Hladka, Jan Netik.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

